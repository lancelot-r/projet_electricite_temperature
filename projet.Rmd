---
title: "Untitled"
output: 
  pdf_document: 
    number_sections: true
  html_document: default
date: "2025-02-05"
editor_options:
  chunk_output_type: inline
---

```{r setup, include=FALSE}
library(car)
knitr::opts_chunk$set(echo = F, warning=FALSE)
```

# Introduction

La consommation énergétique et les variations de température sont deux phénomènes interdépendants qui jouent un rôle crucial dans la gestion des ressources et la planification des infrastructures. La température influence directement la demande énergétique, notamment à travers les besoins en climatisation lors des épisodes de chaleur. Comprendre cette relation et modéliser ces dynamiques est essentiel pour anticiper les pics de consommation, optimiser la production d'énergie et réduire les coûts associés.

L'objectif de cette étude est d'analyser la consommation énergétique en fonction des variations de température dans la période estivale (Juillet-Aout) et d'explorer notamment comment les modèles de lissage exponentiel (comme Holt-Winters) et les modèles SARIMA peuvent être utilisés pour prédire la demande énergétique et les fluctuations climatiques. Enfin, cette dernière sera l'occasion de s'intéresser à plusieurs moyens de calcul de corrélation entre la demande en énergie et les variations de température.

# Données

Les données analysées dans le cadre de ce projet ont été relevées en 2017 dans la ville de Tetouan, au nord du Maroc (10375 km², estimation à 583374 habitants en 2017). Localisée le long de la mer mediterranée, la température est élevée et l'atmosphère est sèche  durant la période d'été.

Ces données contiennent $n = 52416$ relevés qui, toutes les 10 minutes, fournissent les informations (variables) suivantes : 

```{r include=FALSE}
library(dplyr)
library(lubridate)
library(readr)
library(hms)
library(zoo)
library(forecast)
library(tseries)
library(modelsummary)
library(float)

data <- read.csv("~/github/projet_electricite_temperature/data/powerconsumption.csv", header=T)

data$conso = 
  data$PowerConsumption_Zone1+
  data$PowerConsumption_Zone2+
  data$PowerConsumption_Zone3

data = data %>%
  select(-PowerConsumption_Zone1, -PowerConsumption_Zone2, -PowerConsumption_Zone3, -Humidity, -WindSpeed, -GeneralDiffuseFlows, -DiffuseFlows)

data$Datetime <- as.POSIXct(data$Datetime, format="%m/%d/%Y %H:%M")

data_ete <- data %>%
  filter(month(Datetime) == 7 | month(Datetime) == 8) %>%
  filter(minute((Datetime)) == 0) %>%
  filter(day(Datetime) <= 31)

data_test <- data %>%
  filter((month(Datetime) == 7 | month(Datetime) == 8) |
         (month(Datetime) == 9 & day(Datetime) <= 3)) %>%
  filter(minute(Datetime) == 0)
```

```{r, echo = F}
print("Variables : 'Datetime' (date), 'Temperature' (°c), 'conso' (KW/h)")
```

Afin de faciliter l'analyse, les données de consommation d'énergie provenant des trois fournisseurs existants (Zone1, Zone2, Zone3) ont été rassemblées en une seule mesure ($conso$) décrivant la consommation totale, en KWh, pour la ville de Tetouan. Aussi, nous allons rassembler les données par heures, afin d'avoir $24$ mesures pour une journée, puis trier les données pour ne garder que la période estivale (Debut : 01/07, fin : 31/08) donnant $T = 63$ $[1:63]$ jours et $t=1488$ mesures au total.

```{r, echo = F}
datasummary_skim(data_ete)
```

Sur les données de *data_ete* (Juillet / Aout) :

Pour la $Temperature$, celle-ci varie de 19°c à 40°c, avec une moyenne journalière de 26,5°c.

Pour la $conso$, celle-ci varie de $42642.2$ KW/h à $133194.1$ KW/h, avec une moyenne journalière de $87964.8$ KW/h.

Aucune valeur manquante ni valeur abérante n'est à déplorer dans les données.

L'analyse sera séparée en 3 temps : l'analyse de la variable $Temperature$, l'analyse de la variable $conso$ et l'analyse de la corrélation entre les deux mesures.

# Analyse des séries temporelles

## Temperature

```{r}
ts_temp = ts(data_ete$Temperature, frequency = 24, start = c(1,1))
decompose_temp = decompose(ts_temp)
plot(decompose_temp)
```

A partir de la décomposition de la série temporelle *st_temperature* :

1) La tendance semble linéaire : malgré les fluctuations visibles, la période estivale analysée donne l'intuition de températures relativement constantes dans les deux mois selectionnés **CALCULER LES MOYENNES*
2) Une saisonalité journalière semble se dessiner : l'intuition derrière cette analyse est que malgré une tendance constante, les températures baissent la nuit avant de remonter en journée (pic haut à 14, pic bas à 6h **A VERIFIER**)

Comme la trend a une amplitude de moins de 10°C sur une période de plus de 60 jours, il ne semble pas nécessaire de modéliser la tendance autrement que par la température moyenne de cette dernière sous peine de complexifier le modèle. Néanmoins, on peut essayer d'ajuster un modèle linéaire. Sans grande surprise, le coefficient directeur de la droite de regression est de l'ordre de $-10^{-3}$. Nous ferons le choix de ne pas modéliser la trend pour le moment : lorsque nous effectuerons le test de kpss de stationnarité, celui-ci montrera s'il reste une part de tendance dans notre partie résiduelle.

Maintenant, analysons l'ACF et le Partial ACF de la série temporelle afin de pouvoir selectionner et paramétrer au mieux le modèle final :

```{r}
acf(ts_temp, main="ts_temp", lag.max = 192, ylim = c(-1, 1))
```

- La forme de sinusoïde de l'ACF montre une saisonalité claire à chaque lag (toutes les 24h) (ce qui vient confirmer l'intuition de départ). Ainsi, nous allons commencer par modéliser notre série avec un modèle SARIMA en ajoutant une différenciation saissonière (D=1). Le test kpss donnera ensuite une indication sur la stationnarité ou non des résidus de notre modèle **ATTENTION A LA FORMULATION**.

```{r}
par(mfrow=c(1,3))
manual_arima_temp=arima(ts_temp, order = c(0, 0, 0), seasonal = list(order = c(0, 1, 0), period = 24))
kpss.pval = kpss.test(manual_arima_temp$residuals)$p.value
acf(manual_arima_temp$residuals, lag.max = 96, ylim = c(-1, 1))
pacf(manual_arima_temp$residuals, lag.max = 96, ylim = c(-1, 1))
text(1.2,0.7,paste("pval kpss=",round(kpss.pval,3)))

qqPlot(manual_arima_temp$residuals)
```
- l'ACF nous montre que la différenciation saissonière appliquée a bien permis de supprimer la saissonalité (le pattern sinusoidal a disparu).
- Le test kpss (non-signiifcatif) indique que les résidus de notre modèle sont stationnaires : en plus de la suppression effective de la saissonalité par différenciation, le test nous montre aussi qu'il n'est pas nécessaire de modéliser la trend par différenciation car celle-ci n'est pas présente dans nos résidus (elle n'influence pas la stationnarité dans notre cas).
- Le fait que l'ACF et le PACF sont significatifs à chaque lag nous pousse a appliquer un terme auto-régressif (PACF) et de moyenne mobile (ACF) tout deux saisonniers (P = 1, Q = 1).
- Sur le PACF, deux pics sont significatifs poue chaque période, ce qui nous pousse a prendre un terme auto-regressif d'ordre 2 (p = 2).


Analysons maintenant les résidus de notre modèle final SARIMA(2,0,0)(1,1,1)[24]

```{r}
manual_arima_temp=arima(ts_temp, order = c(2, 0, 0), seasonal = list(order = c(1, 1, 1), period = 24))
pB = Box.test(manual_arima_temp$residuals,type="Ljung")$p.value
par(mfrow=c(1,3))
acf(manual_arima_temp$residuals, main="arima manuel - ACF", ylim = c(-1, 1));pacf(manual_arima_temp$residuals, ylim = c(-1, 1), main = "arima manuel - PACF")
text(0.7,0.7,paste("pval BL=",round(pB,3)))
qqPlot(manual_arima_temp$residuals)
```

Selon les deux graphiques, la quasi-totalité des variation sisgnificatives ont été captées par notre modèle. Le test de Box vient confirmer cette intuition en montrant que les résidus de notre modèle sont bien un bruit blanc (test non significatif).

**PARLER EN TERME D'AIC**

Après analyse, les perturbations du modèle semblent homoscédastiques : l'intuition sur la non-variabilité des température moyennes durant ces deux mois viennent confirmer l'analyse, même si les résidus ne sont pas parfaitement homoscédastiques (**test de Breuch-Pagan d'heteroscédasticité significatif**) **EXPLIQUER L'INTUITION AVEC LA TEMPERATURE**
Les résidus du modèle ne suivent pas une loi normale : la distribution de nos rédidus reste **fortement leptokurtique** et **asymétrique à droite**. 

En réalité, nous n'effectuons pas de test paramétriques sur nos modèles. De plus, l'objectif principal étant la modélisation à très court-terme, nous vons choisi de négliger les hypothèses d'homoscédasticité (parfaite) et de normalité des résidus. Il ne faudra donc pas tenir compte des intervalles de confiance dont le calcul sur R n'est valable que pour des résidus suivant une loi normale. 

Afin de s'assurer de la pertinence de notre modèle, nous allons le comparer aux modèles conçus par les algorithmes *auto.arima*, configurés en fonction du BIC, afin d'avoir une meilleure prévision au long terme (en effet, un BIC moins élevé suggère un modèle plus robuste) et au modèle de lissage exponentiel automatique de Holt-Winters *ets* **EXPLIQUER UN PEU POURQUOI C'EST BIEN POUR NOTRE MODELE ET QU'EST CE QUE çA PEUT AIDER A CAPTURER EN +**. Ces modèles seront utilisés pour prédire, à 3 jours, la température à chaque heure. Le graphique en rouge, utilisé comme référence, représente les valeurs réelles de température issue de nos données pour le septembre-01.

```{r}
auto_arima_temp <- auto.arima(ts_temp, ic = "bic")
ets_temp <- ets(ts_temp)
```


```{r}
pred_arima <- forecast(manual_arima_temp, h = 192)
pred_auto_arima <- forecast(auto_arima_temp, h = 192)
pred_ets_temp <- forecast(ets_temp, h = 192)

ts_test_temp = ts(data_test$Temperature, start = c(1,1), frequency = 24)

plot(ts_test_temp, xlim = c(63,66), ylim = c(10, 40),
     xlab = "Date", ylab = "Consommation électrique (kWh)",
     main = "Comparaison des modèles de prévision", col = "black", lwd = 3)

lines(pred_arima$mean, col = "green")
lines(pred_auto_arima$mean, col = "blue")
lines(pred_ets_temp$mean, col = "orange")
```

```{r}
# Calculer les métriques pour chaque modèle
accuracy_manual_arima <- round(accuracy(manual_arima_temp), 3)
accuracy_auto_arima <- round(accuracy(auto_arima_temp), 3)
accuracy_ets <- round(accuracy(ets_temp), 3)

# Extraire les AIC et BIC de chaque modèle
aic_manual_arima <- round(manual_arima_temp$aic, 3)

aic_auto_arima <- round(auto_arima_temp$aic, 3)

aic_ets <- round(ets_temp$aic, 3)

# Créer un tableau de comparaison avec AIC et BIC
comparison_table <- rbind(
  c("Manual ARIMA", aic_manual_arima, accuracy_manual_arima),
  c("Auto ARIMA", aic_auto_arima, accuracy_auto_arima),
  c("ETS", aic_ets, accuracy_ets)
)

# Convertir en dataframe pour un affichage propre
comparison_df <- as.data.frame(comparison_table)
colnames(comparison_df) <- c("Modele", "AIC", "ME", "RMSE", "MAE", "MPE", "MAPE", "MASE", "ACF1")

# Afficher le tableau avec kable
library(knitr)
kable(comparison_df, digits = 4, caption = "Performances de prédiction des modèles")
```

# Consommation électrique

```{r}
ts_conso = ts(data_ete$conso, frequency = 24, start = c(1,1))
decompose_conso = decompose(ts_conso)
plot(decompose_conso)
```

A partir de la décomposition de la  séri temporelle *ts_consommation* :
La trend est comprise entre environ 70000 et 100000 kWh (amplitude de 30000 kWh). Cette dernière est globalement croissante sur le mois de juillet puis décroissante sur le mois d'août. 
On constate une saisonalité journalière avec une amplitude de 60000 kWh (consommation minimale à 6h et maximale à 20h)

- La tendance est ici non négligeable, comprise entre 70000 et 100000 kWh (amplitude de 30000 kWh). Il sera donc important d'appliquer une différenciation dans notre modèe afin de capter cette tendance.
- Il y'a une forte saissonalité journalière ici aussi,avec une amplitude de 60000 kWh (consommation minimale à 6h et maximale à 20h) : en effet, en partant des analyses de température, celles-ci chutent la nuit à une température acceptable sans chauffage (20°c) et remontent en journée vers des températures très hautes (entre 30 et 40 degrés) nécéssitant, si disponible, l'utilisation de climatisation **PARLER AUSSI DE LA PRESENCE A LA MAISON ET DU FAIT QUE C'EST LA CONSO TOTALE ET NON PAS DES MENAGES**, qui est source de consommation energétique. Ainsi, selon cette intuition, cette saissonalité serait présente à chaque temp (toutes les 24h). Il sera aussi important d'appliquer une différenciation saisonnière afin de capter la saissonalité de nos données.

Afin de confirmer nos intuitions, regardons l'ACF de la série temporelle :

```{r}
acf(ts_conso, main="ts_conso", lag.max = 192, ylim = c(-1, 1))
```

```{r}
manual_arima_conso = arima(ts_conso, order = c(0, 1, 0), seasonal = list(order = c(0, 1, 0), period = 24))
kpss.pval = kpss.test(manual_arima_temp$residuals)$p.value
pB <- Box.test(manual_arima_conso$residuals,type="Ljung")$p.value
par(mfrow=c(1,3))
acf(manual_arima_conso$residuals, main="arima manuel - ACF", ylim = c(-1, 1));pacf(manual_arima_conso$residuals, ylim = c(-1, 1), main = "arima manuel - PACF")
text(0.6,0.7,paste("pval kpss=",round(kpss.pval,3)))
text(0.6,0.5,paste("pval Box=",round(pB,3)))
qqPlot(manual_arima_conso$residuals)
```
- L'ACF et le PACF montrent des pics significatifs à chaque période (tout les 24 pics) montrant ainsi une saissonalité dans les deux graphs **A REFORMULER**. Afin de corriger cela, nous applliquerons un paramètre auto-régressif et de moyenne mobile saissonier d'ordre 1 ($P = 1, Q = 1$).
- On voit le premier pic du PACF significatif. Ainsi, nous allons appliquer un terme auto-régressif d'ordre $p = 1$.

```{r}
manual_arima_conso = arima(ts_conso, order = c(1, 1, 0), seasonal = list(order = c(1, 1, 1), period = 24))
pB <- Box.test(manual_arima_conso$residuals,type="Ljung")$p.value
par(mfrow=c(1,3))
acf(manual_arima_conso$residuals, main="arima manuel - ACF", ylim = c(-1, 1));pacf(manual_arima_conso$residuals, ylim = c(-1, 1), main = "arima manuel - PACF")
text(0.7,0.7,paste("pval BL=",round(pB,3)))
qqPlot(manual_arima_conso$residuals)
```
Selon les deux graphiques, la quasi-totalité des variation sisgnificatives ont été captées par notre modèle. Le test de Box vient confirmer cette intuition en montrant que les résidus de notre modèle sont bien un bruit blanc (test non significatif).

```{r}
auto_arima_conso <- auto.arima(ts_conso, ic = "bic")
ets_conso <- ets(ts_conso)
```

```{r}
pred_arima <- forecast(manual_arima_conso, h = 192)
pred_auto_arima <- forecast(auto_arima_conso, h = 192)
pred_ets_temp <- forecast(ets_conso, h = 192)

ts_test_conso = ts(data_test$conso, start = c(1,1), frequency = 24)

plot(ts_test_conso, xlim = c(63,66), ylim = c(40000, 120000),
     xlab = "Date", ylab = "Consommation électrique (kWh)",
     main = "Comparaison des modèles de prévision", col = "black", lwd = 3)

lines(pred_arima$mean, col = "green")
lines(pred_auto_arima$mean, col = "blue")
lines(pred_ets_temp$mean, col = "orange")
```

```{r}
# Calculer les métriques pour chaque modèle
accuracy_manual_arima <- round(accuracy(manual_arima_conso), 3)
accuracy_auto_arima <- round(accuracy(auto_arima_conso), 3)
accuracy_ets <- round(accuracy(ets_conso), 3)

# Extraire les AIC et BIC de chaque modèle
aic_manual_arima <- round(manual_arima_conso$aic, 3)

aic_auto_arima <- round(auto_arima_conso$aic, 3)

aic_ets <- round(ets_conso$aic, 3)

# Créer un tableau de comparaison avec AIC et BIC
comparison_table <- rbind(
  c("Manual ARIMA", aic_manual_arima, accuracy_manual_arima),
  c("Auto ARIMA", aic_auto_arima, accuracy_auto_arima),
  c("ETS", aic_ets, accuracy_ets)
)

# Convertir en dataframe pour un affichage propre
comparison_df <- as.data.frame(comparison_table)
colnames(comparison_df) <- c("Modele", "AIC", "ME", "RMSE", "MAE", "MPE", "MAPE", "MASE", "ACF1")

# Afficher le tableau avec kable
library(knitr)
kable(comparison_df, digits = 4, caption = "Performances de prédiction des modèles")
```