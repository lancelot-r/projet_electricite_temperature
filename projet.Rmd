---
title: "Untitled"
output: 
  pdf_document: 
    number_sections: true
  html_document: default
date: "2025-02-05"
editor_options:
  chunk_output_type: inline
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = F, warning=FALSE)
```

# Introduction

La consommation énergétique et les variations de température sont deux phénomènes interdépendants qui jouent un rôle crucial dans la gestion des ressources et la planification des infrastructures. La température influence directement la demande énergétique, notamment à travers les besoins en climatisation lors des épisodes de chaleur. Comprendre cette relation et modéliser ces dynamiques est essentiel pour anticiper les pics de consommation, optimiser la production d'énergie et réduire les coûts associés.

L'objectif de cette étude est d'analyser la consommation énergétique en fonction des variations de température dans la période estivale (Juillet-Aout) et d'explorer notamment comment les modèles de lissage exponentiel (comme Holt-Winters) et les modèles SARIMA peuvent être utilisés pour prédire la demande énergétique et les fluctuations climatiques. Enfin, cette dernière sera l'occasion de s'intéresser à plusieurs moyens de calcul de corrélation entre la demande en énergie et les variations de température.

# Données

Les données analysées dans le cadre de ce projet ont été relevées en 2017 dans la ville de Tetouan, au nord du Maroc (10375 km², estimation à 583374 habitants en 2017). Localisée le long de la mer mediterranée, la température est élevée et l'atmosphère est sèche  durant la période d'été.

Ces données contiennent $n = 52416$ relevés qui, toutes les 10 minutes, fournissent les informations (variables) suivantes : 

```{r include=FALSE}
library(car)
library(dplyr)
library(lubridate)
library(readr)
library(hms)
library(zoo)
library(forecast)
library(tseries)
library(modelsummary)
library(float)
library(knitr)

data <- read.csv("~/github/projet_electricite_temperature/data/powerconsumption.csv", header=T)

data$conso = 
  data$PowerConsumption_Zone1+
  data$PowerConsumption_Zone2+
  data$PowerConsumption_Zone3

data = data %>%
  select(-PowerConsumption_Zone1, -PowerConsumption_Zone2, -PowerConsumption_Zone3, -Humidity, -WindSpeed, -GeneralDiffuseFlows, -DiffuseFlows)

data$Datetime <- as.POSIXct(data$Datetime, format="%m/%d/%Y %H:%M")

data_ete <- data %>%
  filter(month(Datetime) == 7 | month(Datetime) == 8) %>%
  filter(minute((Datetime)) == 0) %>%
  filter(day(Datetime) <= 31)

data_test <- data %>%
  filter((month(Datetime) == 7 | month(Datetime) == 8) |
         (month(Datetime) == 9 & day(Datetime) <= 7)) %>%
  filter(minute(Datetime) == 0)
```

```{r, echo = F}
print("Variables : 'Datetime' (date), 'Temperature' (°c), 'conso' (KW/h)")
```

Afin de faciliter l'analyse, les données de consommation d'énergie provenant des trois fournisseurs existants (Zone1, Zone2, Zone3) ont été rassemblées en une seule mesure ($conso$) décrivant la consommation totale, en KWh, pour la ville de Tetouan. Aussi, nous allons rassembler les données par heures, afin d'avoir $24$ mesures pour une journée, puis trier les données pour ne garder que la période estivale (Debut : 01/07, fin : 31/08) donnant $T = 63$ $[1:63]$ jours et $t=1488$ mesures au total.

```{r, echo = F}
datasummary_skim(data_ete)
```

Sur les données de *data_ete* (Juillet / Aout) :

Pour la $Temperature$, celle-ci varie de 19°c à 40°c, avec une moyenne journalière de 26,5°c.

Pour la $conso$, celle-ci varie de $42642.2$ KW/h à $133194.1$ KW/h, avec une moyenne journalière de $87964.8$ KW/h.

Aucune valeur manquante ni valeur abérante n'est à déplorer dans les données.

L'analyse sera séparée en 3 temps : l'analyse de la variable $Temperature$, l'analyse de la variable $conso$ et l'analyse de la corrélation entre les deux mesures.

# Analyse des séries temporelles

## Temperature

```{r}
ts_temp = ts(data_ete$Temperature, frequency = 24, start = c(1,1))
decompose_temp = decompose(ts_temp)
plot(decompose_temp)
```

A partir de la décomposition de la série temporelle *st_temperature* :

1) La tendance semble linéaire : malgré les fluctuations visibles, la période estivale analysée donne l'intuition de températures relativement constantes dans les deux mois selectionnés **CALCULER LES MOYENNES*
2) Une saisonalité journalière semble se dessiner : l'intuition derrière cette analyse est que malgré une tendance constante, les températures baissent la nuit avant de remonter en journée (pic haut à 14, pic bas à 6h **A VERIFIER**)

Comme la trend a une amplitude de moins de 10°C sur une période de plus de 60 jours, il ne semble pas nécessaire de modéliser la tendance autrement que par la température moyenne de cette dernière sous peine de complexifier le modèle. Néanmoins, on peut essayer d'ajuster un modèle linéaire. Sans grande surprise, le coefficient directeur de la droite de regression est de l'ordre de $-10^{-3}$. Nous ferons le choix de ne pas modéliser la trend pour le moment : lorsque nous effectuerons le test de kpss de stationnarité, celui-ci montrera s'il reste une part de tendance dans notre partie résiduelle.

Maintenant, analysons l'ACF et le Partial ACF de la série temporelle afin de pouvoir selectionner et paramétrer au mieux le modèle final :

```{r}
acf(ts_temp, main="ts_temp", lag.max = 192, ylim = c(-1, 1))
```

- La forme de sinusoïde de l'ACF montre une saisonalité claire à chaque lag (toutes les 24h) (ce qui vient confirmer l'intuition de départ). Ainsi, nous allons commencer par modéliser notre série avec un modèle SARIMA en ajoutant une différenciation saissonière (D=1). Le test kpss donnera ensuite une indication sur la stationnarité ou non des résidus de notre modèle **ATTENTION A LA FORMULATION**.

```{r}
par(mfrow=c(1,3))
manual_arima_temp=arima(ts_temp, order = c(0, 0, 0), seasonal = list(order = c(0, 1, 0), period = 24))
kpss.pval = kpss.test(manual_arima_temp$residuals)$p.value
acf(manual_arima_temp$residuals, lag.max = 96, ylim = c(-1, 1))
pacf(manual_arima_temp$residuals, lag.max = 96, ylim = c(-1, 1))
text(1.2,0.7,paste("pval kpss=",round(kpss.pval,3)))

qqPlot(manual_arima_temp$residuals)
```
- l'ACF nous montre que la différenciation saissonière appliquée a bien permis de supprimer la saissonalité (le pattern sinusoidal a disparu).
- Le test kpss (non-signiifcatif) indique que les résidus de notre modèle sont stationnaires : en plus de la suppression effective de la saissonalité par différenciation, le test nous montre aussi qu'il n'est pas nécessaire de modéliser la trend par différenciation car celle-ci n'est pas présente dans nos résidus (elle n'influence pas la stationnarité dans notre cas).
- Le fait que l'ACF et le PACF sont significatifs à chaque lag nous pousse a appliquer un terme auto-régressif (PACF) et de moyenne mobile (ACF) tout deux saisonniers (P = 1, Q = 1).
- Sur le PACF, deux pics sont significatifs poue chaque période, ce qui nous pousse a prendre un terme auto-regressif d'ordre 2 (p = 2).


Analysons maintenant les résidus de notre modèle final SARIMA(2,0,0)(1,1,1)[24]

```{r}
manual_arima_temp=arima(ts_temp, order = c(2, 0, 0), seasonal = list(order = c(1, 1, 1), period = 24))
pB = Box.test(manual_arima_temp$residuals,type="Ljung")$p.value
par(mfrow=c(1,3))
acf(manual_arima_temp$residuals, main="arima manuel - ACF", ylim = c(-1, 1));pacf(manual_arima_temp$residuals, ylim = c(-1, 1), main = "arima manuel - PACF")
text(0.7,0.7,paste("pval BL=",round(pB,3)))
qqPlot(manual_arima_temp$residuals)
```

Selon les deux graphiques, la quasi-totalité des variation sisgnificatives ont été captées par notre modèle. Le test de Box vient confirmer cette intuition en montrant que les résidus de notre modèle sont bien un bruit blanc (test non significatif).

**PARLER EN TERME D'AIC**

Après analyse, les perturbations du modèle semblent homoscédastiques : l'intuition sur la non-variabilité des température moyennes durant ces deux mois viennent confirmer l'analyse, même si les résidus ne sont pas parfaitement homoscédastiques (**test de Breuch-Pagan d'heteroscédasticité significatif**) **EXPLIQUER L'INTUITION AVEC LA TEMPERATURE**
Les résidus du modèle ne suivent pas une loi normale : la distribution de nos rédidus reste **fortement leptokurtique** et **asymétrique à droite**. 

En réalité, nous n'effectuons pas de test paramétriques sur nos modèles. De plus, l'objectif principal étant la modélisation à très court-terme, nous vons choisi de négliger les hypothèses d'homoscédasticité (parfaite) et de normalité des résidus. Il ne faudra donc pas tenir compte des intervalles de confiance dont le calcul sur R n'est valable que pour des résidus suivant une loi normale. 

Afin de s'assurer de la pertinence de notre modèle, nous allons le comparer aux modèles conçus par les algorithmes *auto.arima*, configurés en fonction du BIC, afin d'avoir une meilleure prévision au long terme (en effet, un BIC moins élevé suggère un modèle plus robuste) et au modèle de lissage exponentiel automatique de Holt-Winters *ets* **EXPLIQUER UN PEU POURQUOI C'EST BIEN POUR NOTRE MODELE ET QU'EST CE QUE çA PEUT AIDER A CAPTURER EN +**. Ces modèles seront utilisés pour prédire, à 3 jours, la température à chaque heure. Le graphique en rouge, utilisé comme référence, représente les valeurs réelles de température issue de nos données pour le septembre-01.

```{r}
auto_arima_temp <- auto.arima(ts_temp, ic = "bic")
ets_temp <- ets(ts_temp)
```


```{r}
pred_arima_temp <- forecast(manual_arima_temp, h = 168)
pred_auto_arima_temp <- forecast(auto_arima_temp, h = 168)
pred_ets_temp <- forecast(ets_temp, h = 168)

ts_test_temp = ts(data_test$Temperature, start = c(1,1), frequency = 24)

plot(ts_test_temp, xlim = c(63,70), ylim = c(15, 35),
     xlab = "Date", ylab = "Temperature (°c)",
     main = "Comparaison des modèles de prévision de température", col = "black", lwd = "3", xaxt = "n")
axis(1, at = seq(63, 70, by = 1), labels = c("Sept. 01", "Sept. 02", "Sept. 03", "Sept. 04", "Sept. 05", "Sept. 06", "Sept. 07", "Sept. 08"))

lines(pred_arima_temp$mean, col = "#00e4ff", lwd = 2)
lines(pred_auto_arima_temp$mean, col = "blue", lwd = 2)
lines(pred_ets_temp$mean, col = "#ff00e8", lwd = 2)

for(i in 63:70){
  abline(v = i, lty = 2)
}

legend("topright", 
       legend = c("Données réelles", "SARIMA manuel (2,0,0)(1,1,1)[24]", "Auto-SARIMA (2,0,0)(2,1,0)[24]", "ETS (M,Ad,A)"),
       col = c("black", "#00e4ff", "blue", "#ff00e8"), 
       lwd = c(2, 2, 2, 2), cex = 0.7, bg = "white")
```

Selon ce graphique, nous pouvons voir que les 3 modèles présentent des différences significatives. Le modèle ETS se démarquant davangtage des modèles SARIMA. 
Ainsi, sur les 7 jours : 
- Le modèle manuel ARIMA(2,0,0)(1,1,1)[24] capture relativement bien le pic saissonier du premier jour. Cependant, il surestime les valeurs dans la période creuse, réagit mal aux chutes abruptes de températures et sa précision lors des pics hauts décroit fortement lors des jours suivants (car la saissonalité n'est pas la même en septembre ?).
- Le modèle automatique ARIMA(2,0,0)(2,1,0)[24] capture le pic de manière simmilaire et possède une meilleure adéquation que le modèle manuel lors des chutes abruptes de température. Cependant, il surestime davantage les valeur dans la période creuse par rapport au modèle mauel. Comme ce dernier, sa capacité d'estimation des pics et des variation abruptes décroît avec le temps.
- Le modèle ETS (M,Ad,A) possède une précision élevée dans les creux : il lisse efficacement les variations brutales et ne les surestime pas. Cependant, il sous-estime le pic de température (probablement à cause d'une composante saissonière trop lissée).

Ainsi, le modèle SARIMA manuel serait plus adapté pour les saissonalités marquées au détriment des changement brusques. Le modèle SARIAM automatique est plus flexible pour les fluctuations rapides mais toujours sujet au surajustement. ETS excele pour les tendances lissées et les creux, cependant au détriment des pics de température.
Pour finir, aucun de nos modèles n'est performant lorsque l'on dépasse le deuxième jour.

```{r}
# Fonction RMSE
rmse <- function(actual, predicted) {
  sqrt(mean((actual - predicted)^2))
}

aic_manual_arima_temp <- manual_arima_temp$aic
aic_auto_arima_temp <- auto_arima_temp$aic
aic_ets_temp <- ets_temp$aic

date_j1 = ts_test_temp[1490:1513]
date_j2 = ts_test_temp[1513:1537]
date_j3 = ts_test_temp[1537:1561]
date_j4 = ts_test_temp[1561:1585]
date_j5 = ts_test_temp[1585:1609]
date_j6 = ts_test_temp[1609:1633]
date_j7 = ts_test_temp[1633:1656]

# Création d'un data frame des résultats
rmse_results <- data.frame(
  "Nom du modèle" = c("SARIMA", "Auto-SARIMA", "ETS"),
  AIC = c(aic_manual_arima_temp, aic_auto_arima_temp, aic_ets_temp),
  jour_1 = c(rmse(date_j1, pred_arima_temp$mean[1:24]), rmse(date_j1, pred_auto_arima_temp$mean[1:24]), rmse(date_j1, pred_ets_temp$mean[1:24])),
  jour_2 = c(rmse(date_j2, pred_arima_temp$mean[24:48]), rmse(date_j2, pred_auto_arima_temp$mean[24:48]), rmse(date_j2, pred_ets_temp$mean[24:48])),
  jour_3 = c(rmse(date_j3, pred_arima_temp$mean[48:72]), rmse(date_j3, pred_auto_arima_temp$mean[48:72]), rmse(date_j3, pred_ets_temp$mean[48:72])),
  jour_4 = c(rmse(date_j4, pred_arima_temp$mean[72:96]), rmse(date_j4, pred_auto_arima_temp$mean[72:96]), rmse(date_j4, pred_ets_temp$mean[72:96])),
  jour_5 = c(rmse(date_j5, pred_arima_temp$mean[96:120]), rmse(date_j5, pred_auto_arima_temp$mean[96:120]), rmse(date_j5, pred_ets_temp$mean[96:120])),
  jour_6 = c(rmse(date_j6, pred_arima_temp$mean[120:144]), rmse(date_j6, pred_auto_arima_temp$mean[120:144]), rmse(date_j6, pred_ets_temp$mean[120:144])),
  jour_7 = c(rmse(date_j7, pred_arima_temp$mean[144:168]), rmse(date_j7, pred_auto_arima_temp$mean[144:168]), rmse(date_j7, pred_ets_temp$mean[144:168]))
)

kable(rmse_results, digits = 2, caption = "RMSE des modèles pour la semaine du 01/09 au 07/09")
```

Comme on peut le voir sur ce tableau, le modèle ETS reste, en moyenne, celui qui prédit le mieux avec une varation de l'erreur moyenne ne dépassant pas les $2°c$. Pour les modèles SARIMA, celui constitué manuellement est en moyenne moins précis que le modèle automatique sur les 7 jours.

# Consommation électrique

```{r}
ts_conso = ts(data_ete$conso, frequency = 24, start = c(1,1))
decompose_conso = decompose(ts_conso)
plot(decompose_conso)
```

A partir de la décomposition de la  séri temporelle *ts_consommation* :
La trend est comprise entre environ 70000 et 100000 kWh (amplitude de 30000 kWh). Cette dernière est globalement croissante sur le mois de juillet puis décroissante sur le mois d'août. 
On constate une saisonalité journalière avec une amplitude de 60000 kWh (consommation minimale à 6h et maximale à 20h)

- La tendance est ici non négligeable, comprise entre 70000 et 100000 kWh (amplitude de 30000 kWh). Il sera donc important d'appliquer une différenciation dans notre modèe afin de capter cette tendance.
- Il y'a une forte saissonalité journalière ici aussi,avec une amplitude de 60000 kWh (consommation minimale à 6h et maximale à 20h) : en effet, en partant des analyses de température, celles-ci chutent la nuit à une température acceptable sans chauffage (20°c) et remontent en journée vers des températures très hautes (entre 30 et 40 degrés) nécéssitant, si disponible, l'utilisation de climatisation **PARLER AUSSI DE LA PRESENCE A LA MAISON ET DU FAIT QUE C'EST LA CONSO TOTALE ET NON PAS DES MENAGES**, qui est source de consommation energétique. Ainsi, selon cette intuition, cette saissonalité serait présente à chaque temp (toutes les 24h). Il sera aussi important d'appliquer une différenciation saisonnière afin de capter la saissonalité de nos données.

Afin de confirmer nos intuitions, regardons l'ACF de la série temporelle :

```{r}
acf(ts_conso, main="ts_conso", lag.max = 192, ylim = c(-1, 1))
```

```{r}
manual_arima_conso = arima(ts_conso, order = c(0, 1, 0), seasonal = list(order = c(0, 1, 0), period = 24))
kpss.pval = kpss.test(manual_arima_temp$residuals)$p.value
pB <- Box.test(manual_arima_conso$residuals,type="Ljung")$p.value
par(mfrow=c(1,3))
acf(manual_arima_conso$residuals, main="arima manuel - ACF", ylim = c(-1, 1));pacf(manual_arima_conso$residuals, ylim = c(-1, 1), main = "arima manuel - PACF")
text(0.6,0.7,paste("pval kpss=",round(kpss.pval,3)))
text(0.6,0.5,paste("pval Box=",round(pB,3)))
qqPlot(manual_arima_conso$residuals)
```
- L'ACF et le PACF montrent des pics significatifs à chaque période (tout les 24 pics) montrant ainsi une saissonalité dans les deux graphs **A REFORMULER**. Afin de corriger cela, nous applliquerons un paramètre auto-régressif et de moyenne mobile saissonier d'ordre 1 ($P = 1, Q = 1$).
- On voit le premier pic du PACF significatif. Ainsi, nous allons appliquer un terme auto-régressif d'ordre $p = 1$.

```{r}
manual_arima_conso = arima(ts_conso, order = c(1, 1, 0), seasonal = list(order = c(1, 1, 1), period = 24))
pB <- Box.test(manual_arima_conso$residuals,type="Ljung")$p.value
par(mfrow=c(1,3))
acf(manual_arima_conso$residuals, main="arima manuel - ACF", ylim = c(-1, 1));pacf(manual_arima_conso$residuals, ylim = c(-1, 1), main = "arima manuel - PACF")
text(0.7,0.7,paste("pval BL=",round(pB,3)))
qqPlot(manual_arima_conso$residuals)
```
Selon les deux graphiques, la quasi-totalité des variation sisgnificatives ont été captées par notre modèle. Le test de Box vient confirmer cette intuition en montrant que les résidus de notre modèle sont bien un bruit blanc (test non significatif).

```{r}
auto_arima_conso <- auto.arima(ts_conso, ic = "bic")
ets_conso <- ets(ts_conso)
```

```{r}
pred_arima_conso <- forecast(manual_arima_conso, h = 168)
pred_auto_arima_conso <- forecast(auto_arima_conso, h = 168)
pred_ets_conso <- forecast(ets_conso, h = 168)

ts_test_conso = ts(data_test$conso, start = c(1,1), frequency = 24)

plot(ts_test_conso, xlim = c(63,70), ylim = c(30000, 125000),
     xlab = "Date", ylab = "Consommation électrique (kWh)",
     main = "Comparaison des modèles de prévision de consommation éléctrique", col = "black", lwd = 3, xaxt = "n")
axis(1, at = seq(63, 70, by = 1), labels = c("Sept. 01", "Sept. 02", "Sept. 03", "Sept. 04", "Sept. 05", "Sept. 06", "Sept. 07", "Sept. 08"))
lines(pred_arima_conso$mean, col = "#00e4ff", lwd = 2)
lines(pred_auto_arima_conso$mean, col = "blue", lwd = 2)
lines(pred_ets_conso$mean, col = "#ff00e8", lwd = 2)
for(i in 63:70){
  abline(v = i, lty = 2)
}

legend("topright", 
       legend = c("Données réelles", "SARIMA manuel (2,0,0)(1,1,1)[24]", "Auto-SARIMA (2,0,0)(2,1,0)[24]", "ETS (M,Ad,A)"),
       col = c("black", "#00e4ff", "blue", "#ff00e8"), 
       lwd = c(2, 2, 2, 2), cex = 0.7, bg = "white")
```

Le graphique nous montre un evenement spécial lors du premier jour, evènement absolument pas capté par les modèles de prévisions.

Selon ce graphique :
- On voit que les modèles SARIMA manuel et automatique sont très simmilaires dans leurs estimations. Les pics de basse consommation sont bien estimés lors des deux premiers jours mais sous-estimés de manière croissant ensuite. Ils estiment bien les pics hauts à partir du jour 2 (**POURQUOI**) et captent davantage les variations intermédiaires (chute partielle de consommation avant atteinte du pic). Les variations abruptes sont aussi bien estimées. Cependant, ces deux modèles tendent à sous-estimer les valeurs réelles avec le temps, toute heure confondue.
- Le modèle ETS est meilleur que les modèles SARIMA pour estimer les pics base de consommation, mais il a tendance a surestimer les pics hauts, surtout lors des premiers jours. Aussi, malgré une moins bonne estiamtion des variations intermédiaires et des pics hauts comparé aux deux autres modèles, ETS estime mieux et de manière plus stable la consommation, là où les modèles SARIMA perdent fortement en précision dans le temps.

Les pics journaliers montrent qu'ETS surestime mais suit la tendance globale, tandis que les modèles SARIMA divergent. Les creux nocturnes relèvent une sous-estimation critique des modèles SARIMA.
Ainsi, pour la gestion des pics, ETS ets plus fiable grace a sa capacité à prévoir des amplitudes élevées, et est aussi optimal pour les prévisions nocturnes.

```{r}
aic_manual_arima_conso <- manual_arima_conso$aic
aic_auto_arima_conso <- auto_arima_conso$aic
aic_ets_conso <- ets_conso$aic

date_j1 = ts_test_conso[1489:1513]
date_j2 = ts_test_conso[1513:1537]
date_j3 = ts_test_conso[1537:1561]
date_j4 = ts_test_conso[1561:1585]
date_j5 = ts_test_conso[1585:1609]
date_j6 = ts_test_conso[1609:1633]
date_j7 = ts_test_conso[1633:1656]

# Création d'un data frame des résultats
rmse_results <- data.frame(
  "Nom du  modèle" = c("SARIMA", "Auto-SARIMA", "ETS"),
  AIC = c(aic_manual_arima_conso, aic_auto_arima_conso, aic_ets_conso),
  jour_1 = c(rmse(date_j1, pred_arima_conso$mean[1:24]), rmse(date_j1, pred_auto_arima_conso$mean[1:24]), rmse(date_j1, pred_ets_conso$mean[1:24])),
  jour_2 = c(rmse(date_j2, pred_arima_conso$mean[24:48]), rmse(date_j2, pred_auto_arima_conso$mean[24:48]), rmse(date_j2, pred_ets_conso$mean[24:48])),
  jour_3 = c(rmse(date_j3, pred_arima_conso$mean[48:72]), rmse(date_j3, pred_auto_arima_conso$mean[48:72]), rmse(date_j3, pred_ets_conso$mean[48:72])),
  jour_4 = c(rmse(date_j4, pred_arima_conso$mean[72:96]), rmse(date_j4, pred_auto_arima_conso$mean[72:96]), rmse(date_j4, pred_ets_conso$mean[72:96])),
  jour_5 = c(rmse(date_j5, pred_arima_conso$mean[96:120]), rmse(date_j5, pred_auto_arima_conso$mean[96:120]), rmse(date_j5, pred_ets_conso$mean[96:120])),
  jour_6 = c(rmse(date_j6, pred_arima_conso$mean[120:144]), rmse(date_j6, pred_auto_arima_conso$mean[120:144]), rmse(date_j6, pred_ets_conso$mean[120:144])),
  jour_7 = c(rmse(date_j7, pred_arima_conso$mean[144:168]), rmse(date_j7, pred_auto_arima_conso$mean[144:168]), rmse(date_j7, pred_ets_conso$mean[144:168]))
)
kable(rmse_results, digits = 2, caption = "RMSE des modèles pour la semaine du 01/09 au 07/09")
```

Comme on le voit sur ce tableau, le modèle ETS est en moyenne moins précis que les modèles SARIMA pour les 4 premiers jours (différence d'erreur de $3000$ KWh), mais cette tendance s'inverse ensuite et ETS devient largement plus précis que les modèles SARIMA (diférence d'erreur moyenne de $10000$ KWh à j+7).

Les pics journaliers montrent qu'ETS surestime mais suit la tendance globale, tandis que les modèles SARIMA divergent. Les creux nocturnes relèvent une sous-estimation critique des modèles SARIMA.
Ainsi, pour la gestion des pics, ETS sera plus fiable grace a sa capacité à prévoir des amplitudes élevées, et est aussi optimal pour les prévisions nocturnes. Cependant, si l'on cherche à estimer la consommation au court terme dans les périodes intermédiaires, les modèles SARIMA seront plus adaptés.
Enfin, aucun des modèles n'arrive à capter le changement brutal du preimer jour (**QUEL JOUR C'EST**). Ces modèles ne sont donc pas robustes aux evenements rares et critiques.

