---
title: "Untitled"
output: 
  pdf_document: 
    number_sections: true
  html_document: default
date: "2025-02-05"
editor_options:
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = F)
```

# Introduction

La consommation énergétique et les variations de température sont deux phénomènes interdépendants qui jouent un rôle crucial dans la gestion des ressources et la planification des infrastructures. La température influence directement la demande énergétique, notamment à travers les besoins en climatisation lors des épisodes de chaleur. Comprendre cette relation et modéliser ces dynamiques est essentiel pour anticiper les pics de consommation, optimiser la production d'énergie et réduire les coûts associés.

L'objectif de cette étude est d'analyser la consommation énergétique en fonction des variations de température dans la période estivale (Juillet-Aout) et d'explorer notamment comment les modèles de lissage exponentiel (comme Holt-Winters) et les modèles SARIMA peuvent être utilisés pour prédire la demande énergétique et les fluctuations climatiques. Enfin, cette dernière sera l'occasion de s'intéresser à plusieurs moyens de calcul de corrélation entre la demande en énergie et les variations de température.

# Données

Les données analysées dans le cadre de ce projet ont été relevées en 2017 dans la ville de Tetouan, au nord du Maroc (10375 km², estimation à 583374 habitants en 2017). Localisée le long de la mer mediterranée, la température est élevée et l'atmosphère est sèche  durant la période d'été.

Ces données contiennent $n = 52416$ relevés qui, toutes les 10 minutes, fournissent les informations (variables) suivantes : 

```{r include=FALSE}
library(dplyr)
library(lubridate)
library(readr)
library(hms)
library(zoo)
library(forecast)
library(tseries)
library(modelsummary)
library(float)

data <- read.csv("~/github/projet_electricite_temperature/data/powerconsumption.csv", header=T)

data$conso = 
  data$PowerConsumption_Zone1+
  data$PowerConsumption_Zone2+
  data$PowerConsumption_Zone3

data = data %>%
  select(-PowerConsumption_Zone1, -PowerConsumption_Zone2, -PowerConsumption_Zone3, -Humidity, -WindSpeed, -GeneralDiffuseFlows, -DiffuseFlows)

data$Datetime <- as.POSIXct(data$Datetime, format="%m/%d/%Y %H:%M")

data_ete <- data %>%
  filter(month(Datetime) == 7 | month(Datetime) == 8) %>%
  filter(minute((Datetime)) == 0) %>%
  filter(day(Datetime) <= 31)
```

```{r, echo = F}
print("Variables : 'Datetime' (date), 'Temperature' (°c), 'conso' (KW/h)")
```

Afin de faciliter l'analyse, les données de consommation d'énergie provenant des trois fournisseurs existants (Zone1, Zone2, Zone3) ont été rassemblées en une seule mesure ($conso$) décrivant la consommation totale, en KWh, pour la ville de Tetouan. Aussi, nous allons rassembler les données par heures, afin d'avoir $24$ mesures pour une journée, puis trier les données pour ne garder que la période estivale (Debut : 01/07, fin : 31/08) donnant $T = 63$ $[1:63]$ jours et $t=1488$ mesures au total.

```{r, echo = F}
datasummary_skim(data_ete)
```

Sur les données de *data_ete* (Juillet / Aout) :

Pour la $Temperature$, celle-ci varie de 19°c à 40°c, avec une moyenne journalière de 26,5°c.

Pour la $conso$, celle-ci varie de $42642.2$ KW/h à $133194.1$ KW/h, avec une moyenne journalière de $87964.8$ KW/h.

Aucune valeur manquante ni valeur abérante n'est à déplorer dans les données.

L'analyse sera séparée en 3 temps : l'analyse de la variable $Temperature$, l'analyse de la variable $conso$ et l'analyse de la corrélation entre les deux mesures.

# Analyse des séries temporelles

## Temperature

```{r}
ts_temp = ts(data_ete$Temperature, frequency = 24, start = c(1,1))
decompose_temp = decompose(ts_temp)
plot(decompose_temp)
```

A partir de la décomposition de la série temporelle *st_temperature* :

1) La tendance semble linéaire : malgré les fluctuations visibles, la période estivale analysée donne l'intuition de températures relativement constantes dans les deux mois selectionnés
2) Une saisonalité journalière semble se dessiner : l'intuition derrière cette analyse est que malgré une tendance constante, les températures baissent la nuit avant de remonter en journée (pic haut à 14, pic bas à 6h **A VERIFIER**)
3) La partie résiduelle **A COMPLETER**

Comme la trend a une amplitude de moins de 10°C sur une période de plus de 60 jours, il ne semble pas nécessaire de modéliser la tendance autrement que par la température moyenne de cette dernière sous peine de complexifier le modèle. Néanmoins, on peut essayer d'ajuster un modèle linéaire. Sans grande surprise, le coefficient directeur de la droite de regression est de l'ordre de $-10^{-3}$. Toutefois, ce choix va influencer le **test kpss de non-stationnarité** car ce dernier, à la différence du **test de racine unitaire augmenté de Dickey-Fuller**, va détecter la trend non modélisée avec comme conséquence une non-stationnarité de la série. **ATTENTION ON DOIT CHOISIR SI OUI OU NON ON MODELISE LA TREND ET EXPLIQUER EXPLICITEMENT LE CHOIX**

```{r, include=F}
par(mfrow=c(1,2))
plot(decompose(diff(ts_temp))$trend)
plot(decompose_temp$trend)
```

```{r, include = F}
t<-1:length(ts_temp)
t1<-ts(t,start=c(1,0),freq=24)
mod_trend_lin=lm(decompose_temp$trend~t1)
summary(mod_trend_lin)
```

```{r, include = F}
plot.ts(decompose_temp$trend, ylim=c(23,33))
abline(mod_trend_lin$coefficients)
#abline(h=mean(decompose_temp$trend, na.rm = T), col='red')
```

```{r, include=F}
par(mfrow=c(3,1))
plot(decompose(diff(ts_temp))$trend)
plot(decompose_temp$trend)
plot(decompose_temp$trend-mod_trend_lin$fitted.values, na.rm=T)
```

```{r}
kpss.test(ts_temp-mod_trend_lin$fitted.values)
```

Maintenant, analysons l'ACF et le Partial ACF de la série temporelle afin de pouvoir selectionner et paramétrer au mieux le modèle final :

```{r}
par(mfrow=c(1,2))
acf(ts_temp, main="ts_temp - est.trend", lag.max = 192)
pacf(ts_temp)
```


- Pour l'ACF, la forme de sinusoïde montre une saisonalité claire, toutes les 24h (ce qui vient confirmer l'intuition de départ). Les "pics" aux lags 2 à 8 suggère une part de type moyenne-mobile dans le modèle.
- Par ailleurs, pour le partial ACF, les "pics" aux lags 1 et 2 suggère une part de type auto-regressive de paramètre 2.

On part donc sur un modèle ARIMA de paramètre (p=2,i=0,q).
Pour choisir le paramètre q, on choisit le modèle minimisant l'AIC (ce choix sera justifié plus tard)

```{r}
par(mfrow=c(1,1))
ARIMA_AIC_list=c()
for (q in 0:5) {
  mod=arima(ts_temp, order = c(2, 0, q))
  ARIMA_AIC_list=c(ARIMA_AIC_list, mod$aic)
}
plot(0:5,ARIMA_AIC_list, type='b')
```

On voit que pour q=2, l'AIC est de 3544 alors qu'il est de 3541 pour q=3. Nous avons fait le choix de ne pas trop complexifier le modèle quitte à perdre en précisions : ainsi, nous choisissons q=2.

```{r}
par(mfrow=c(2,1))
mod1=arima(ts_temp, order = c(2, 0, 2))
acf(mod1$residuals, lag.max = 96)
pacf(mod1$residuals, lag.max = 96)
```
```{r}
Box.test(mod1$residuals,type="Ljung")$p.value
```

Bien que le test de Box-Ljung admet une p-valeur de 0.82, l'acf et le pacf montre des "pics" à chaque période. Ceci est un symptome de saisonnalité ; le modèle permettant de mieux modéliser la partie résiduelle est donc un modèle SARIMA. 
Les pics aux lags 24 sur l'acf et le pacf suggère un modèle SARIMA(p=2,i=0,q=2)(P=1,D=1,Q=1)[24]

```{r}
par(mfrow=c(1,2))
manual_arima_temp=arima(ts_temp, order = c(1, 0, 2), seasonal = list(order = c(1, 1, 1), period = 24))
acf(manual_arima_temp$residuals, lag.max = 96)
pacf(manual_arima_temp$residuals, lag.max = 96)
```

Il nous resterait à comparer les aic de tous les modèles SARIMA tels que $P+D+Q=3$ mais on trouverait que le modèle précédent a l'aic le plus bas. 
```{r}
Box.test(manual_arima_temp$residuals,type="Ljung")$p.value
```

On constate que le test de Box-Ljung admet une p-valeur encore plus proche de 1 et que les pics symptomatiques du modèle ARIMA sont moins prononcés et plus rares. De plus, l'AIC affiché est meilleur : 3161 pour le modèle SARIMA contre 3544 pour le modèle ARIMA. On retiendra donc le nouveau modèle.

Le **test de racine unitaire augmenté de Dickey Fuller** sur la partie résiduelle de nos données étant **significative**, nous avons fait le choix de constituer **ATTENTION ON IGNORE LA TREND OU NON ?*

Nous avons donc fait le choix de constituer un modèle $\text{ARIMA(p = 1, d = 0, q = 2)(P = 1, D = 1, Q = 1)[24]}$ : ce modèle contient un terme auto-régressif d'ordre $p = 1$, aucun terme de différenciation car la série est supposée stationnaire **ATTENTION MODELISATION OU NON TREND**, un terme de moyenne mobile d'ordre $q = 1$. Pour la partie saisonnière, celle-ci a été modélisée 

```{r}
par(mfrow=c(2,1))
manual_arima_temp = arima(ts_temp, order = c(2, 0, 2), seasonal = list(order = c(1, 1, 1), period = 24)) # = auto.arima()
```

```{r}
pB <- Box.test(manual_arima_temp$residuals,type="Ljung")$p.value
par(mfrow=c(1,2))
acf(manual_arima_temp$residuals, main="arima manuel - ACF", ylim = c(-1, 1));pacf(manual_arima_temp$residuals, ylim = c(-1, 1), main = "arima manuel - PACF")
text(0.7,0.7,paste("pval BL=",round(pB,3)))
```

**PEUT ETRE RAJOUER DES COMPARAISONS AVEC D'AUTRES MODELES ?? AIC ??**

Le test de **Ljung-Box** indique que les résidus de notre modèle ARIMA est un bruit blanc (au seuil $\alpha = 99\%$). De plus; l'interprétation graphique de l'ACF et du PACF nous indique que notre modèle capture la quasi-totalité des variations non-aléatoires de notre série temporelle. 

Après analyse, les perturbations du modèle semblent homoscédastiques : l'intuition sur la non-variabilité des température moyennes durant ces deux mois viennent confirmer l'analyse, même si les résidus ne sont pas parfaitement heteroscédastiques (**test de Breuch-Pagan d'heteroscédasticité significatif**) **EXPLIQUER L'INTUITION AVEC LA TEMPERATURE**
Les résidus du modèle ne suivent pas une loi normale : malgré **l'absence de skew (distribution centrée)**, la distribution de nos rédidus reste **fortement leptokurtique**. 

En réalité, nous n'effectuons pas de test paramétriques sur nos modèles. De plus, l'objectif principal étant la modélisation à très court-terme, nous vons choisi de négliger les hypothèses d'homoscédasticité (parfaite) et de normalité des résidus. Il ne faudra donc pas tenir compte des intervalles de confiance dont le calcul sur R n'est valable que pour des résidus suivant une loi normale. 

Afin de s'assurer de la pertinence de notre modèle, nous allons le comparer aux modèles conçus par les algorithmes *auto.arima*, configurés en fonction du BIC, afin d'avoir une meilleure prévision au long terme (en effet, un BIC moins élevé suggère un modèle plus robuste) et au modèle de lissage exponentiel automatique de Holt-Winters *ets* **EXPLIQUER UN PEU POURQUOI C'EST BIEN POUR NOTRE MODELE ET QU'EST CE QUE çA PEUT AIDER A CAPTURER EN +**. Ces modèles seront utilisés pour prédire, à 3 jours, la température à chaque heure. Le graphique en rouge, utilisé comme référence, représente les valeurs réelles de température issue de nos données pour le septembre-01.

```{r}
auto_arima_temp <- auto.arima(ts_temp, ic = "bic")
ets_temp <- ets(ts_temp)
```

```{r}
pred_arima <- forecast(manual_arima_temp, h = 192)
pred_auto_arima <- forecast(auto_arima_temp, h = 192)
pred_ets_temp <- forecast(ets_temp, h = 192)

par(mfrow = c(1, 4))
xlim_start <- as.POSIXct("2017-09-01 00:00:00")
xlim_end <- as.POSIXct("2017-09-03 23:00:00")

plot(data$Datetime, data$Temperature, col = "red", type = "l", 
     xlim = c(xlim_start, xlim_end),
     xlab = "Date", ylab = "Temperature (°c)", 
     main = "Données réeles", ylim = c(10, 40))

plot(pred_arima, xlim = c(63, 66), ylim = c(10, 40), main = "manual-ARIMA\n(1,0,2)(1,1,1)[24]",
     xlab = "Date", ylab = "Temperature (°c)",)
plot(pred_auto_arima, xlim = c(63, 66), ylim = c(10, 40), main = "auto-ARIMA\n(2,0,0)(2,1,0)[24]",
     xlab = "Date", ylab = "Temperature (°c)",)
plot(pred_ets_temp, xlim = c(63, 66), ylim = c(10, 40), main = "ets\n(M,Ad,A)",
     xlab = "Date", ylab = "Temperature (°c)")
```

```{r}
# Calculer les métriques pour chaque modèle
accuracy_manual_arima <- round(accuracy(manual_arima_temp), 3)
accuracy_auto_arima <- round(accuracy(auto_arima_temp), 3)
accuracy_ets <- round(accuracy(ets_temp), 3)

# Extraire les AIC et BIC de chaque modèle
aic_manual_arima <- round(manual_arima_temp$aic, 3)

aic_auto_arima <- round(auto_arima_temp$aic, 3)

aic_ets <- round(ets_temp$aic, 3)

# Créer un tableau de comparaison avec AIC et BIC
comparison_table <- rbind(
  c("Manual ARIMA", aic_manual_arima, accuracy_manual_arima),
  c("Auto ARIMA", aic_auto_arima, accuracy_auto_arima),
  c("ETS", aic_ets, accuracy_ets)
)

# Convertir en dataframe pour un affichage propre
comparison_df <- as.data.frame(comparison_table)
colnames(comparison_df) <- c("Modele", "AIC", "ME", "RMSE", "MAE", "MPE", "MAPE", "MASE", "ACF1")

# Afficher le tableau avec kable
library(knitr)
kable(comparison_df, digits = 4, caption = "Performances de prédiction des modèles")
```

# Consommation électrique

```{r}
ts_conso = ts(data_ete$conso, frequency = 24, start = c(1,1))
decompose_conso = decompose(ts_conso)
plot(decompose_conso)
```

```{r}
par(mfrow=c(1,1))
plot(decompose_conso$random)
```

La trend est comprise entre environ 70000 et 100000 kWh (amplitude de 30000 kWh). Cette dernière est globalement croissante sur le mois de juillet puis décroissante sur le mois d'août. 
On constate une saisonalité journalière avec une amplitude de 60000 kWh (consommation minimale à 6h et maximale à 20h)
Enfin, la partie résiduelle **A COMPLETER**


```{r, include = F}
t<-1:length(ts_conso)
t1<-ts(t,start=c(1,0),freq=24)
mod_conso_lin=lm(decompose_conso$trend~t1)
summary(mod_conso_lin)
```

```{r, include = F}
plot.ts(decompose_conso$trend)
abline(mod_conso_lin$coefficients)
#abline(h=mean(decompose_temp$trend, na.rm = T), col='red')
```

```{r}
plot(decompose(diff(ts_conso)))
```


```{r}
par(mfrow=c(1,2))
acf(diff(ts_conso), lag.max = 96)
pacf(diff(ts_conso), lag.max = 96)

```

L'acf et le pacf montre une saisonalité claire. 
Essayons d'abord de modéliser la consommation à l'aide d'un modèle ARIMA : si ce dernier ne s'avère pas assez précis, nous nous orienterons vers un modèle SARIMA. 
L'acf et le pacf suggère d'abord un modèle ARIMA(1,1,2)

```{r}
mod_conso_arima=arima(ts_conso, order = c(1, 1, 2), seasonal = list(order = c(0, 0, 0), period = 24))
par(mfrow=c(1,2))
acf(mod_conso_arima$residuals, lag.max = 96)
pacf(mod_conso_arima$residuals, lag.max = 96)
```

On constate mieux l'aspect saisonnier de la série temporelle. Les pics sur l'acf et le pacf suggère alors un modèle SARIMA(1,1,2)(1,1,1)[24].

```{r}
mod_conso_sarima=arima(ts_conso, order = c(1, 1, 2), seasonal = list(order = c(1, 2, 2), period = 24))
par(mfrow=c(1,2))
acf(mod_conso_sarima$residuals, lag.max = 96)
pacf(mod_conso_sarima$residuals, lag.max = 96)
```

```{r}
auto_arima_conso <- auto.arima(ts_conso, ic = "bic")
ets_conso <- ets(ts_conso)
```


```{r}
acf(auto_arima_conso$residuals, lag.max = 96)
pacf(auto_arima_conso$residuals, lag.max = 96)
```

```{r}
pred_arima <- forecast(mod_conso_sarima, h = 192)
pred_auto_arima <- forecast(auto_arima_conso, h = 192)
pred_ets_temp <- forecast(ets_conso, h = 192)

par(mfrow = c(1, 4))
xlim_start <- as.POSIXct("2017-09-01 00:00:00")
xlim_end <- as.POSIXct("2017-09-03 23:00:00")

plot(data$Datetime, data$conso, col = "red", type = "l", 
     xlim = c(xlim_start, xlim_end),
     xlab = "Date", ylab = "Consommation électrique (kWh)", 
     main = "Données réeles", ylim=c(40000,120000))

plot(pred_arima, main = "manual-ARIMA\n(1,1,2)(1,2,2)[24]",
     xlab = "Date", ylab = "Consommation électrique (kWh)", xlim = c(63, 66), ylim = c(40000,120000))
plot(pred_auto_arima, main = "auto-ARIMA\n(0,1,1)(0,1,1)[24]",
     xlab = "Date", ylab = " (°c)",xlim = c(63, 66), ylim = c(40000,120000))
plot(pred_ets_temp, main = "ets\n(M,Ad,A)",
     xlab = "Date", ylab = "consommation électrique (kWh)", xlim = c(63, 66), ylim = c(40000,120000))
```

```{r}
# Calculer les métriques pour chaque modèle
accuracy_manual_arima <- round(accuracy(mod_conso_sarima), 3)
accuracy_auto_arima <- round(accuracy(auto_arima_conso), 3)
accuracy_ets <- round(accuracy(ets_conso), 3)

# Extraire les AIC et BIC de chaque modèle
aic_manual_arima <- round(mod_conso_sarima$aic, 3)

aic_auto_arima <- round(auto_arima_conso$aic, 3)

aic_ets <- round(ets_conso$aic, 3)

# Créer un tableau de comparaison avec AIC et BIC
comparison_table <- rbind(
  c("Manual ARIMA", aic_manual_arima, accuracy_manual_arima),
  c("Auto ARIMA", aic_auto_arima, accuracy_auto_arima),
  c("ETS", aic_ets, accuracy_ets)
)

# Convertir en dataframe pour un affichage propre
comparison_df <- as.data.frame(comparison_table)
colnames(comparison_df) <- c("Modele", "AIC", "ME", "RMSE", "MAE", "MPE", "MAPE", "MASE", "ACF1")

# Afficher le tableau avec kable
library(knitr)
kable(comparison_df, digits = 4, caption = "Performances de prédiction des modèles")
```